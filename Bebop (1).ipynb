{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.46.131.161:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Bebop</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb6ab255750>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "from ast import literal_eval\n",
    "sc = SparkContext(\"local\", \"Bebop\")\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = sqlContext.sparkSession\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------------+---------+--------------------+\n",
      "|InvoiceNo|Customer_ID|               Date|   Planet|            Purchase|\n",
      "+---------+-----------+-------------------+---------+--------------------+\n",
      "|   536365|    17850.0|        Dec 01 2010|   Abydos|[{'ItemNo': u'851...|\n",
      "|   536366|    17850.0|              40513|   Abydos|[{'ItemNo': 22633...|\n",
      "|   536367|    13047.0|         12/01/2010|   Abydos|\"[{'ItemNo': 8487...|\n",
      "|   536368|    13047.0|        Dec 01 2010|   Abydos|[{'ItemNo': 22960...|\n",
      "|   536369|    13047.0|         12/01/2010|   Abydos|[{'ItemNo': 21756...|\n",
      "|   536370|    12583.0|              40513|Altair IV|[{'ItemNo': 22728...|\n",
      "|   536371|    13748.0|2010-12-01 09:00:00|   Abydos|[{'ItemNo': 22086...|\n",
      "|   536372|    17850.0|              40513|   Abydos|[{'ItemNo': 22632...|\n",
      "|   536373|    17850.0|        Dec 01 2010|   Abydos|[{'ItemNo': u'851...|\n",
      "|   536374|    15100.0|              40513|   Abydos|[{'ItemNo': 21258...|\n",
      "|   536375|    17850.0|              40513|   Abydos|[{'ItemNo': u'851...|\n",
      "|   536376|    15291.0|        Dec 01 2010|   Abydos|[{'ItemNo': 22114...|\n",
      "|   536377|    17850.0|        Dec 01 2010|   Abydos|[{'ItemNo': 22632...|\n",
      "|   536378|    14688.0|2010-12-01 09:37:00|   Abydos|[{'ItemNo': 22386...|\n",
      "|   536380|    17809.0|2010-12-01 09:41:00|   Abydos|[{'ItemNo': 22961...|\n",
      "|   536381|    15311.0|2010-12-01 09:41:00|   Abydos|\"[{'ItemNo': 2213...|\n",
      "|   536382|    16098.0|              40513|   Abydos|[{'ItemNo': 10002...|\n",
      "|   536384|    18074.0|              40513|   Abydos|[{'ItemNo': 82484...|\n",
      "|   536385|    17420.0|              40513|   Abydos|[{'ItemNo': 22783...|\n",
      "|   536386|    16029.0|        Dec 01 2010|   Abydos|[{'ItemNo': 84880...|\n",
      "+---------+-----------+-------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data.csv\",header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "matching date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert 01/04/2011 format to 2011-04-01 00:00:00 format\n",
    "convert_monthdateformat = F.udf(lambda s: datetime.datetime.strptime(s,\"%m/%d/%Y\").strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "df_date_convert_monthdateformat = df.filter(F.col(\"Date\").rlike(r\"\\d{2}/\\d{2}/\\d{4}\"))\n",
    "df_date_convert_monthdateformat = df_date_convert_monthdateformat.withColumn(\"Date\",convert_monthdateformat(df_date_convert_monthdateformat[\"Date\"]))\n",
    "# convert Jan 04 2011 format to 2011-04-01 00:00:00 format\n",
    "convert_monthletterformat = F.udf(lambda s: datetime.datetime.strptime(s,\"%b %d %Y\").strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "df_date_convert_monthletterformat = df.filter(F.col(\"Date\").rlike(r\"[A-Za-z]{3}\\s\\d{2}\\s\\d{4}\"))\n",
    "df_date_convert_monthletterformat = df_date_convert_monthletterformat.withColumn(\"Date\",convert_monthletterformat(df_date_convert_monthletterformat[\"Date\"]))\n",
    "# convert 5 digit code format (40886) to 2011-04-01 00:00:00 format\n",
    "convert_digitformat = F.udf(lambda s: (datetime.date(1899,12,30)+datetime.timedelta(days=int(s))).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "df_date_convert_digitformat = df.filter(F.col(\"Date\").rlike(r\"\\d{5}\"))\n",
    "df_date_convert_digitformat = df_date_convert_digitformat.withColumn(\"Date\",convert_digitformat(df_date_convert_digitformat[\"Date\"]))\n",
    "# capture 2011-04-01 00:00:00 format dates\n",
    "df_actualformat = df.filter(F.col(\"Date\").rlike(r\"\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2}\"))\n",
    "# combine all date formats\n",
    "Bebop_df = df_date_convert_monthdateformat.union(df_date_convert_monthletterformat).union(df_date_convert_digitformat).union(df_actualformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[InvoiceNo: string, Customer_ID: string, Date: string, Planet: string, Purchase: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bebop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Changing data types InvoiceNo: INT, Customer_ID: INT, Date: Date, Planet: string, Purchase, string\n",
    "Bebop_df = Bebop_df.withColumn(\"InvoiceNo\",Bebop_df[\"InvoiceNo\"].cast(IntegerType()))\n",
    "Bebop_df = Bebop_df.withColumn(\"Customer_ID\",Bebop_df[\"Customer_ID\"].cast(IntegerType()))\n",
    "# Bebop_df = Bebop_df.withColumn(\"Date\",Bebop_df[\"Date\"].cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[InvoiceNo: int, Customer_ID: int, Date: string, Planet: string, Purchase: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bebop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Bebop_df.createOrReplaceTempView(\"Bebop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table vn0hxf8.bebop as select * from Bebop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating invoices table\n",
    "spark.sql(\"CREATE TABLE vn0hxf8.invoices AS SELECT InvoiceNo,Customer_ID,Date,Planet FROM vn0hxf8.bebop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''CREATE TABLE vn0hxf8.orders AS\n",
    "SELECT invoiceno,Customer_ID, ItemNo,CAST(UnitPrice AS DOUBLE) AS UnitPrice, CAST(TRIM(Quantity) AS INT) AS Quantity FROM(\n",
    "SELECT invoiceno,Customer_ID, CASE WHEN ItemNo LIKE \"%'%\" THEN SUBSTRING(ItemNo,4,LENGTH(ItemNo)-4) ELSE ItemNo END AS ItemNo, UnitPrice, Quantity FROM(\n",
    "SELECT invoiceno,Customer_ID,\n",
    "split(split(results,\",\")[0],':')[1] AS  ItemNo,\n",
    "regexp_replace(split(split(results,\",\")[1],':')[1], \"[\\\\]|}]\", \"\") AS UnitPrice,\n",
    "regexp_replace(split(split(results,\",\")[3],':')[1], \"[\\\\]|}]\", \"\") AS Quantity\n",
    "FROM (SELECT invoiceno,Customer_ID, split(translate(purchase, '\"\\\\[|]|\\\"\"',''), \"}, \") AS r\n",
    "FROM vn0hxf8.bebop) t1 LATERAL VIEW explode(r) rr AS results ) data_cleaning) convert_data_types''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''CREATE TABLE vn0hxf8.product AS\n",
    "SELECT invoiceno, ItemNo,CAST(UnitPrice AS DOUBLE) AS UnitPrice, Description FROM(\n",
    "SELECT invoiceno, CASE WHEN ItemNo LIKE \"%'%\" THEN SUBSTRING(ItemNo,4,LENGTH(ItemNo)-4) ELSE ItemNo END AS ItemNo, UnitPrice, \n",
    "CASE WHEN Description LIKE \"%'%\" THEN SUBSTRING(Description,4,LENGTH(Description)-4) ELSE Description END AS Description FROM(\n",
    "SELECT invoiceno,\n",
    "       split(split(results,\",\")[0],':')[1] AS  ItemNo,\n",
    "       regexp_replace(split(split(results,\",\")[1],':')[1], \"[\\\\]|}]\", \"\") AS UnitPrice,\n",
    "       regexp_replace(split(split(results,\",\")[2],':')[1], \"[\\\\]|}]\", \"\") AS Description\n",
    "    FROM\n",
    "       (SELECT invoiceno,\n",
    "             split(translate(purchase, '\"\\\\[|]|\\\"\"',''), \"}, \") AS r\n",
    "       FROM vn0hxf8.bebop) t1 LATERAL VIEW explode(r) rr AS results) data_cleaning) convert_data_types''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|   col_name|data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|  InvoiceNo|      int|   null|\n",
      "|Customer_ID|      int|   null|\n",
      "|       Date|   string|   null|\n",
      "|     Planet|   string|   null|\n",
      "+-----------+---------+-------+\n",
      "\n",
      "+---------+-----------+-------------------+------+\n",
      "|InvoiceNo|Customer_ID|Date               |Planet|\n",
      "+---------+-----------+-------------------+------+\n",
      "|536367   |13047      |2010-12-01 00:00:00|Abydos|\n",
      "|536369   |13047      |2010-12-01 00:00:00|Abydos|\n",
      "|536388   |16250      |2010-12-01 00:00:00|Abydos|\n",
      "|536400   |13448      |2010-12-01 00:00:00|Abydos|\n",
      "|536405   |14045      |2010-12-01 00:00:00|Abydos|\n",
      "+---------+-----------+-------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#invoices table\n",
    "spark.sql(\"desc vn0hxf8.invoices\").show()\n",
    "# sample data\n",
    "spark.sql(\"select * from vn0hxf8.invoices\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|   col_name|data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|  invoiceno|      int|   null|\n",
      "|Customer_ID|      int|   null|\n",
      "|     ItemNo|   string|   null|\n",
      "|  UnitPrice|   double|   null|\n",
      "|   Quantity|      int|   null|\n",
      "+-----------+---------+-------+\n",
      "\n",
      "+---------+-----------+------+---------+--------+\n",
      "|invoiceno|Customer_ID|ItemNo|UnitPrice|Quantity|\n",
      "+---------+-----------+------+---------+--------+\n",
      "|   536371|      13748| 22086|     2.55|      80|\n",
      "|   536378|      14688| 22386|     1.95|      10|\n",
      "|   536378|      14688|85099C|     1.95|      10|\n",
      "|   536378|      14688| 21033|     2.95|      10|\n",
      "|   536378|      14688| 20723|     0.85|      10|\n",
      "+---------+-----------+------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# orders table\n",
    "spark.sql(\"desc vn0hxf8.orders\").show()\n",
    "# sample data\n",
    "spark.sql(\"select * from vn0hxf8.orders\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|   col_name|data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|  invoiceno|      int|   null|\n",
      "|     ItemNo|   string|   null|\n",
      "|  UnitPrice|   double|   null|\n",
      "|Description|   string|   null|\n",
      "+-----------+---------+-------+\n",
      "\n",
      "+---------+------+---------+--------------------+\n",
      "|invoiceno|ItemNo|UnitPrice|         Description|\n",
      "+---------+------+---------+--------------------+\n",
      "|   536365|85123A|     2.55|    ADORIAN CROSSBOW|\n",
      "|   536365| 71053|     3.39| WHITE METAL LANTERN|\n",
      "|   536365|84406B|     2.75|CREAM CUPID HEART...|\n",
      "|   536365|84029G|     3.39|KNITTED UNION FLA...|\n",
      "|   536365|84029E|     3.39|RED WOOLLY HOTTIE...|\n",
      "+---------+------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# product table\n",
    "spark.sql(\"desc vn0hxf8.product\").show()\n",
    "# sample data\n",
    "spark.sql(\"select * from vn0hxf8.product\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " Data Model\n",
    "![title](DM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|unique_customers|\n",
      "+----------------+\n",
      "|            4373|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UNIQUE CUSTOMERS\n",
    "spark.sql('''SELECT COUNT(*) AS unique_customers FROM (SELECT Customer_ID FROM vn0hxf8.invoices GROUP BY Customer_ID)\n",
    "             unique_customers''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2\n",
    "SELECT Customer_ID, SUM(revenue_per_invoice) AS total_revenue FROM(\n",
    "ORDER BY total_revenue desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|second_biggest_customer|\n",
      "+-----------------------+\n",
      "|                  14646|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# second biggest customer\n",
    "spark.sql('''SELECT Customer_ID AS second_biggest_customer FROM (\n",
    "SELECT Customer_ID, SUM(revenue_per_invoice) AS total_revenue FROM(\n",
    "SELECT Customer_ID, (Quantity*UnitPrice) AS revenue_per_invoice FROM vn0hxf8.orders WHERE Customer_ID IS NOT NULL\n",
    "AND Quantity IS NOT NULL) subquery GROUP BY Customer_ID ORDER BY total_revenue desc LIMIT 2)\n",
    "subquery1 ORDER BY total_revenue LIMIT 1 ''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|total_multi_planet_customers|\n",
      "+----------------------------+\n",
      "|                           8|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of customers visited multiple planets\n",
    "spark.sql('''SELECT COUNT(*) AS total_multi_planet_customers FROM (\n",
    "SELECT Customer_ID, COLLECT_SET(Planet) AS Planets_list FROM vn0hxf8.invoices WHERE Customer_ID IS NOT NULL\n",
    "GROUP BY Customer_ID) multi_planet_customers WHERE SIZE(Planets_list) > 1''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|most_price_changes_product|\n",
      "+--------------------------+\n",
      "|                         M|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most price changes product\n",
    "spark.sql(''' SELECT ItemNo AS most_price_changes_product FROM (\n",
    "          SELECT ItemNo,COLLECT_SET(UnitPrice) AS changes_list FROM vn0hxf8.orders GROUP BY ItemNo\n",
    "          ) price_changes ORDER BY SIZE(changes_list) DESC LIMIT 1''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|most_attracted_item|\n",
      "+-------------------+\n",
      "|              22423|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most attracted item\n",
    "spark.sql('''SELECT ItemNo as most_attracted_item FROM(\n",
    "SELECT ItemNo, COLLECT_SET(Customer_ID) AS customers_list FROM vn0hxf8.orders WHERE Customer_ID IS NOT NULL\n",
    "GROUP BY ItemNo ) subquery ORDER BY SIZE(customers_list) DESC LIMIT 1\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Customer_ID|\n",
      "+-----------+\n",
      "|      12403|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# customer - shortest average length of time between purchases\n",
    "spark.sql(''' SELECT Customer_ID FROM (\n",
    "SELECT Customer_ID, AVG(time_diff) AS average_purchase_time FROM (\n",
    "SELECT Customer_ID,CAST(UNIX_TIMESTAMP(Date) - UNIX_TIMESTAMP(previous_date) AS DOUBLE) as time_diff FROM(\n",
    "SELECT Customer_ID,Date,LAG(Date,1) over(Partition BY Customer_ID order by Date) as previous_date FROM vn0hxf8.invoices\n",
    "WHERE Customer_ID IS NOT NULL order by Customer_ID) timediff) avg_time WHERE time_diff IS NOT NULL GROUP BY Customer_ID\n",
    ")shorest_avg_time_customer ORDER BY average_purchase_time LIMIT 1''').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|combined_revenue|\n",
      "+----------------+\n",
      "|        20223.52|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total revenue of top 3 items\n",
    "spark.sql(''' SELECT SUM(total_revenue) AS combined_revenue FROM(\n",
    "SELECT InvoiceNo, ItemNo, SUM(revenue) AS total_revenue FROM(\n",
    "SELECT InvoiceNo, ItemNo, UnitPrice*Quantity as revenue, COUNT(ItemNo) OVER (PARTITION BY InvoiceNo) as items_per_invoice\n",
    "FROM vn0hxf8.orders WHERE InvoiceNo IS NOT NULL) subquery WHERE items_per_invoice >=3 GROUP BY InvoiceNo, ItemNo\n",
    "ORDER BY total_revenue DESC LIMIT 3)subquery1''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mystery(array):\n",
    "    mylist = []\n",
    "    for i in range(len(array)):\n",
    "        for j in range(len(array)):\n",
    "            elem1 = array[i]\n",
    "            elem2 = array[j]\n",
    "            if elem1 == elem2 and i!=j:\n",
    "                if elem2 not in mylist:\n",
    "                    mylist.append(elem2)\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1\n",
    "mystery function returns DUPLICATE elements in input array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2\n",
    "Run time complexity of mystery function is O(N * N)\n",
    "Space Complexity O(N)\n",
    "-- Where N is length of array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Efficient solution\n",
    "def duplicates(array):\n",
    "        duplicate_list = []\n",
    "        unique_list = []\n",
    "        \n",
    "        for elem in array:\n",
    "            if elem in unique_list:\n",
    "                duplicate_list.append(elem)\n",
    "            else:\n",
    "                unique_list.append(elem)\n",
    "        return duplicate_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4\n",
    "Run time complexity of mystery function is O(N)\n",
    "Space Complexity O(2*N)\n",
    "-- Where N is length of array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5\n",
    "mystery function is a two dimensional array and each element is compared based on its indices resulting O(N*N) time complexity with space complexiy of O(N) for storing results in mylist.\n",
    "duplicates function iterates input array once and stores duplicates if the element is not present in unique list. This function is optimized resulting O(N) time complexity with space complexity of O(2*N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
